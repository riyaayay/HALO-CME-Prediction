{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1. Import Required Libraries"
      ],
      "metadata": {
        "id": "nsioDbFO0gFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sunpy.map import Map\n",
        "from spacepy import pycdf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, LSTM, Dense, Concatenate, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "# Reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "EMO62AW5zZcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Global Configurations"
      ],
      "metadata": {
        "id": "wcoz2kG_1Kon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "VELC_DIR = 'velc_data/'     # Path to .fits images\n",
        "ASPEX_DIR = 'aspex_data/'   # Path to .cdf files\n",
        "IMG_SIZE = (128, 128)       # Resize for CNN\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "NUM_SAMPLES = 1000          # Limit for efficiency\n"
      ],
      "metadata": {
        "id": "PZbfs_xjza98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Preprocessing Functions"
      ],
      "metadata": {
        "id": "7eqKCu2r1JHD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3IncY1hzLPy"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_velc(file_path):\n",
        "    velc_map = Map(file_path)\n",
        "    data = velc_map.data.astype(np.float32)\n",
        "    resized = tf.image.resize(data[None, ..., None], IMG_SIZE) / 255.0\n",
        "    return resized.numpy().squeeze()\n",
        "\n",
        "def preprocess_aspex(file_path):\n",
        "    cdf_data = pycdf.CDF(file_path)\n",
        "    df = pd.DataFrame(cdf_data['data'])  # Adjust variable name as needed\n",
        "    flux = df['proton_flux'].values      # Replace with real key\n",
        "    return tf.keras.preprocessing.sequence.pad_sequences([flux], maxlen=100, dtype='float32')[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Batch Loader"
      ],
      "metadata": {
        "id": "N90E_IX01HtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_data(batch_start, batch_size):\n",
        "    velc_files = sorted(os.listdir(VELC_DIR))[:NUM_SAMPLES]\n",
        "    aspex_files = sorted(os.listdir(ASPEX_DIR))[:NUM_SAMPLES]\n",
        "\n",
        "    velc_batch = [os.path.join(VELC_DIR, f) for f in velc_files[batch_start:batch_start + batch_size]]\n",
        "    aspex_batch = [os.path.join(ASPEX_DIR, f) for f in aspex_files[batch_start:batch_start + batch_size]]\n",
        "\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        velc_data = list(executor.map(preprocess_velc, velc_batch))\n",
        "        aspex_data = list(executor.map(preprocess_aspex, aspex_batch))\n",
        "\n",
        "    labels = np.random.randint(0, 2, size=len(velc_batch))  # Synthetic binary labels\n",
        "    return (np.array(velc_data), np.array(aspex_data)), labels\n"
      ],
      "metadata": {
        "id": "BYaZwwSK0oDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Aggregate Data"
      ],
      "metadata": {
        "id": "pG5lFzmk1GP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "all_velc_data, all_aspex_data, all_labels = [], [], []\n",
        "for i in range(0, NUM_SAMPLES, BATCH_SIZE):\n",
        "    (velc_batch, aspex_batch), labels = load_data(i, BATCH_SIZE)\n",
        "    all_velc_data.append(velc_batch)\n",
        "    all_aspex_data.append(aspex_batch)\n",
        "    all_labels.append(labels)\n",
        "\n",
        "velc_data = np.concatenate(all_velc_data)\n",
        "aspex_data = np.concatenate(all_aspex_data)\n",
        "labels = np.concatenate(all_labels)\n",
        "\n",
        "# Reshape ASPEX input for LSTM\n",
        "aspex_data = aspex_data.reshape((-1, 100, 1))\n"
      ],
      "metadata": {
        "id": "4XQoVQ1J0sLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Train-Test Split"
      ],
      "metadata": {
        "id": "cu8S60Jv1E9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "velc_train, velc_test, aspex_train, aspex_test, y_train, y_test = train_test_split(\n",
        "    velc_data, aspex_data, labels, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "ORHoC3bd0w0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. ATSFusion Model"
      ],
      "metadata": {
        "id": "apKyNjST1Dkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_atsfusion():\n",
        "    # VELC CNN branch\n",
        "    velc_input = Input(shape=(128, 128, 1))\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(velc_input)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "\n",
        "    # ASPEX LSTM branch\n",
        "    aspex_input = Input(shape=(100, 1))\n",
        "    y = LSTM(64)(aspex_input)\n",
        "    y = Dense(64, activation='relu')(y)\n",
        "\n",
        "    # Fusion\n",
        "    fused = Concatenate()([x, y])\n",
        "    fused = Dense(32, activation='relu')(fused)\n",
        "    output = Dense(1, activation='sigmoid')(fused)\n",
        "\n",
        "    model = Model(inputs=[velc_input, aspex_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "atsfusion = build_atsfusion()\n",
        "atsfusion.summary()\n"
      ],
      "metadata": {
        "id": "pGr2WRAM00qA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Training"
      ],
      "metadata": {
        "id": "0hGeOSk31B39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = atsfusion.fit(\n",
        "    [velc_train, aspex_train], y_train,\n",
        "    validation_data=([velc_test, aspex_test], y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n"
      ],
      "metadata": {
        "id": "dlWewn6H03oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Visualization"
      ],
      "metadata": {
        "id": "zGABl2411AeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Val')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Val')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tGGfP53j05ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Evaluation"
      ],
      "metadata": {
        "id": "slYg17Yx0-kS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_loss, test_accuracy = atsfusion.evaluate([velc_test, aspex_test], y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# Sample prediction\n",
        "sample_idx = 0\n",
        "pred = atsfusion.predict([velc_test[sample_idx:sample_idx+1], aspex_test[sample_idx:sample_idx+1]])\n",
        "print(f\"Predicted CME Probability: {pred[0][0]:.4f} | Actual: {y_test[sample_idx]}\")\n"
      ],
      "metadata": {
        "id": "ktjZdsF_05rC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}